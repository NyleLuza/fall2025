{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d95f8ed",
   "metadata": {},
   "source": [
    "# Author: Nyle Luza\n",
    "# Assignment 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7241683c",
   "metadata": {},
   "source": [
    "## Problem 1: Knowledge Q & A (60% + 10% extra)\n",
    "\n",
    "• Answering the following questions about the data transformation and dimension reduc-\n",
    "tion.\n",
    "\n",
    "• Don’t use any python library while solving these questions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec7dfe2",
   "metadata": {},
   "source": [
    "1) True or false, in the decision tree algorithm, after we have calculated the informa-\n",
    "tion gain of each attributes regarding the object, we could always process the feature\n",
    "selection. Explain your answer.\n",
    "\n",
    "    - This is false because having using just information gain itself could lead to overfitting since IG elects attributes with more classes as node. This could lead to biased and overfitted models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b917153",
   "metadata": {},
   "source": [
    "2) True or false, in the decision tree algorithm, after we have calculated the information gain of each attributes regarding the object, we could always construct the whole\n",
    "decision tree. Explain your answer.\n",
    "    \n",
    "    - False, because the information must be recalculated at each node"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb7f6e8b",
   "metadata": {},
   "source": [
    "3) Suppose you have the following 2-itemsets candidates and their support counts, with a\n",
    "minimum support threshold of 3:\n",
    "Using the Apriori algorithm, list all of the potential 3-itemsets, also indicates it\n",
    "can/cannot be frequent, explain your answers\n",
    "    \n",
    "    - "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
